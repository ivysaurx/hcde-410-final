{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ccbed5-4e95-4834-a0b2-15d896c15532",
   "metadata": {},
   "source": [
    "## Preparing the Dataset\n",
    "The dataset we are using is **OtomeGames.csv**, which we will make readable by Python with the two code chunks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23139d3-1dbd-4e3c-b40a-d51a2fc11114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def prepare_datasets(file_path):\n",
    "    \"\"\" \n",
    "    Accepts: path to a tab-separated plaintext file\n",
    "    Returns: a list containing a dictionary for every row in the file, \n",
    "        with the file column headers as keys\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path) as infile:\n",
    "        reader = csv.DictReader(infile, delimiter=',')\n",
    "        list_of_dicts = [dict(r) for r in reader]\n",
    "        \n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d804b537-ec76-4ade-938d-bb4b2dcf29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "otome_games = prepare_datasets(\"csvfiles/OtomeGames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e718c04-9d66-4c2c-a33a-7dcc4d2d6ff1",
   "metadata": {},
   "source": [
    "Below, we clean up the empty cells in the dataset and replace them with NaN values. Then we take the relevant pieces of numerical data and convert them from string to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df11675-e2ce-4e24-93cb-7d7e36714e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "games_df = pd.DataFrame(otome_games)\n",
    "games_df.replace('', np.nan, inplace=True)\n",
    "games_df[['NoLI', 'NoFemale', 'NoFemaleLI', 'NoFemaleFI', 'NoLGBT', 'Copies1stWeek', 'CopiesTotal']] = games_df[['NoLI', 'NoFemale', 'NoFemaleLI',\n",
    "                                                                                                                 'NoFemaleFI', 'NoLGBT','Copies1stWeek', 'CopiesTotal']].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6063861-99d8-442e-9a77-0326200c0226",
   "metadata": {},
   "source": [
    "## Separating First Week Sales and Total Copies Sold\n",
    "Because we are trying to optimize both Copies1stWeek and CopiesTotal, we will be creating two separate Pandas DataFrame objects, each one having the same independent variables but with different dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9640d39-327f-4c0b-8d8a-3eb21639c454",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_games_df = games_df[['Year', 'Copies1stWeek', 'CopiesTotal', 'NoLI', 'NoFemale', 'NoFemaleLI', 'NoFemaleFI', 'NoLGBT']]\n",
    "\n",
    "firstweek_df = rel_games_df.drop(\"CopiesTotal\", axis=1)\n",
    "totalsales_df = rel_games_df.drop(\"Copies1stWeek\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7170af47-07e1-4aea-a2e2-977c6853039e",
   "metadata": {},
   "source": [
    "# Making a Model for Copies1stWeek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ae9c8-8535-4d58-a0a4-689cb68dae2c",
   "metadata": {},
   "source": [
    "First we'll copy the dataset to predict the copies sold during its first week after release. Since there are empty cells in within Copies1stWeek for some otome games, we dropped the values that contained NaN within Copies1stWeek.\n",
    "We then assign NoLI, NoFemale, NoFemaleLI, NoFemaleFI, and NoLGBT as independent variables (x) and Copies1stWeek as a dependent variable (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ef61e3-7bb0-42fa-97c7-79d6e5f67752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split data into features and label \n",
    "firstweek_df.dropna(subset=['Copies1stWeek'], inplace=True)\n",
    "x = firstweek_df[['NoLI', 'NoFemale', 'NoFemaleLI', 'NoFemaleFI', 'NoLGBT']].copy()\n",
    "y = firstweek_df[\"Copies1stWeek\"].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3baa0dc-1461-4bc5-89e1-85f6ddafed62",
   "metadata": {},
   "source": [
    "## Splitting the data into training set and test set\n",
    "Below, we split the data into a training and test set. The training set is 70% of the data, while 30% would be the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc7db6c-a6de-4695-8ceb-b40a59944528",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.7,\n",
    "                                                           random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cafe0-d2c0-41e0-b744-d3f3c479f402",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "We create the model in this next step! Specifically, we create a linear regression model and fit it to the training data and then later apply it to the testing data for the x variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c9b8e9-0c23-4f7f-8a33-f0ca800fd747",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Instnatiating the models \n",
    "model = LinearRegression()\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "# Training the models \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Making predictions with each model\n",
    "lin_reg_preds = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e40b4c0-1384-4cf7-96dc-d7fc6f46ca0a",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "We evaluate the accuracy of the model here by printing out the Mean Squared Error and the R-squared, which we get by comparing the actual values of Copies1stWeek and the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd21c5d-a00c-47d1-827f-2c25b316cc82",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 42877454.16456728\n",
      "R-squared: -0.30999625414575505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# Evaluate the model\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, lin_reg_preds))\n",
    "print(\"R-squared:\", r2_score(y_test, lin_reg_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63aff0-f4cc-4f9e-b5c1-2b3833371feb",
   "metadata": {},
   "source": [
    "The Mean Squared Error measures how close a regression line is to a set of data points, which is y_test in this case. We can see the the mean squared error is a very, VERY, large number, which means that the model itself is NOT accurate. The R-squared typically ranges from 0 to 1 and if there is a negative R-squared, it means the data fits the model extremely poorly. This further confirms that our otome game model is very innaccurate. \n",
    "\n",
    "Nonetheless, let's go on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127060c-f9c4-4444-8d5b-acfba9b547dc",
   "metadata": {},
   "source": [
    "## Using the Model to Optimize the Copies1stWeek\n",
    "First, we look at the coefficients for each one of the five x-variables and the y intercept. Then we create the equation that maximizes sales. We then define the constraints that we see within the datasets (for example, there is a minimum of 1 love interest and a maximum of 19 within the entire **OtomeGames.csv** file).\n",
    "After that, I created some initial guesses on what the optimal values would be. I guessed 7 love interests, 4 female characters, 1 female love interest, 1 female friendship interest, and 0 LGBT characters based on what I saw after scrolling through the data.\n",
    "Then, we ran them all through the equation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc83d20-0881-49b4-9437-026991d3aeb0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  1284.50790959   -483.92110737 -10001.80662107   6450.00063339\n",
      "  -3740.63019054]\n",
      "Intercept: 3584.659952351167\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# Model coefficients (for optimization)\n",
    "print(\"Coefficients:\", model.coef_)  # Effect of each feature on sales\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "# Objective function: negative sales (we minimize this to maximize sales)\n",
    "def objective(features):\n",
    "    # 'NoLI', 'NoFemale', 'NoFemaleLI', 'NoFemaleFI', 'NoLGBT'\n",
    "    noli, nofemale, nofemaleli, nofemalefi, nolgbt = features\n",
    "\n",
    "    return -(model.coef_[0] * noli + model.coef_[1] * nofemale + model.coef_[2] * \n",
    "             nofemaleli + model.coef_[3] * nofemalefi \n",
    "             + model.coef_[4] * nolgbt + \n",
    "             model.intercept_)\n",
    "\n",
    "# Constraints (e.g., x-value ranges)\n",
    "constraints = (\n",
    "    {'type': 'ineq', 'fun': lambda x: x[0] - 1},  # noli >= 1\n",
    "    {'type': 'ineq', 'fun': lambda x: 19 - x[0]},  # noli <= 19\n",
    "    {'type': 'ineq', 'fun': lambda x: x[1] - 1},  # nofemale >= 1\n",
    "    {'type': 'ineq', 'fun': lambda x: 9 - x[1]},  # nofemale <= 9\n",
    "    {'type': 'ineq', 'fun': lambda x: x[2] - 0},  # nofemaleli >= 0\n",
    "    {'type': 'ineq', 'fun': lambda x: 2 - x[2]},  # nofemaleli <= 2\n",
    "    {'type': 'ineq', 'fun': lambda x: x[3] - 0},  # nofemalefi >= 0\n",
    "    {'type': 'ineq', 'fun': lambda x: 3 - x[3]},  # nofemalefi <= 3\n",
    "    {'type': 'ineq', 'fun': lambda x: x[4] - 0},  # nolgbt >= 0\n",
    "    {'type': 'ineq', 'fun': lambda x: 1 - x[4]}  # nolgbt <= 1\n",
    ")\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [7, 4, 1, 1, 0]\n",
    "\n",
    "# Optimize\n",
    "result = minimize(objective, initial_guess, constraints=constraints)\n",
    "optimal_noli, optimal_nofemale, optimal_nofemaleli, optimal_nofemalefi, optimal_nolgbt = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e47043-4eef-4f32-aa5b-bcc71bba6622",
   "metadata": {},
   "source": [
    "# Results: Optimized Values for Copies1stWeek\n",
    "Drumroll!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851f4d92-9002-4e01-bed6-7908ee29969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Number of Love Interests: 19.0000299884407\n",
      "Optimal Number of Female Characters: 0.9999886595493308\n",
      "Optimal Number of Female Love Interests: -0.00023582421090395655\n",
      "Optimal Number of Female Friendship Interests: 3.000152048887685\n",
      "Optimal Number of LGBT characters: -8.820710081636207e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Number of Love Interests:\", optimal_noli)\n",
    "print(\"Optimal Number of Female Characters:\", optimal_nofemale)\n",
    "print(\"Optimal Number of Female Love Interests:\", optimal_nofemaleli)\n",
    "print(\"Optimal Number of Female Friendship Interests:\", optimal_nofemalefi)\n",
    "print(\"Optimal Number of LGBT characters:\", optimal_nolgbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09652010-b121-48f4-8026-138d87726f88",
   "metadata": {},
   "source": [
    "19 love interests! That's a lot!\n",
    "1 female character? That's just the protagonist.\n",
    "0 female love interests? But 3 friendship interests, even though we only have one female character? That's contradictory. And 0 LGBT characters.\n",
    "Keep in mind that this model is extremely innacurate!\n",
    "\n",
    "Time to repeat the process but with CopiesTotal, instead!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e793a-0a71-4381-822f-fbb8cc9b10ea",
   "metadata": {},
   "source": [
    "# Making a Model for CopiesTotal\n",
    "We do the exact same thing, but this time, we change the dependent variable, \"y\", to be **CopiesTotal** instead! The rest of the process is exactly the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0faba4f5-372b-451e-9eae-310ce72581fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 373731315.9722419\n",
      "R-squared: -0.687066828403814\n",
      "Coefficients: [ 2389.02653409  -225.94716741     0.         17060.6281709\n",
      "     0.        ]\n",
      "Intercept: 1549.6157938347715\n"
     ]
    }
   ],
   "source": [
    "totalsales_df.dropna(subset=['CopiesTotal'], inplace=True)\n",
    "x = totalsales_df[['NoLI', 'NoFemale', 'NoFemaleLI', 'NoFemaleFI', 'NoLGBT']].copy()\n",
    "y = totalsales_df[\"CopiesTotal\"].copy() \n",
    "\n",
    "# Split data into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.7,\n",
    "                                                           random_state=25)\n",
    "\n",
    "# Instanatiating the models \n",
    "model = LinearRegression()\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "# Training the models \n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Making predictions with each model\n",
    "lin_reg_preds = model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, lin_reg_preds))\n",
    "print(\"R-squared:\", r2_score(y_test, lin_reg_preds))\n",
    "\n",
    "# Model coefficients (for optimization)\n",
    "print(\"Coefficients:\", model.coef_)  # Effect of each feature on sales\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "result = minimize(objective, initial_guess, constraints=constraints)\n",
    "optimal_noli, optimal_nofemale, optimal_nofemaleli, optimal_nofemalefi, optimal_nolgbt = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907c011-b47e-43cc-a1cd-14940352fd9b",
   "metadata": {},
   "source": [
    "It looks like this model is also very innacurate compared to the actual data, similar to our model for Copies1stWeek.\n",
    "# Results: Optimized Values for CopiesTotal\n",
    "Drumroll #2!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b420a562-a07d-438c-9b79-7b55dd6e12a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Number of Love Interests: 18.99995498937642\n",
      "Optimal Number of Female Characters: 1.0000042261169426\n",
      "Optimal Number of Female Love Interests: 1.0\n",
      "Optimal Number of Female Friendship Interests: 2.9996766522308462\n",
      "Optimal Number of LGBT characters: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal Number of Love Interests:\", optimal_noli)\n",
    "print(\"Optimal Number of Female Characters:\", optimal_nofemale)\n",
    "print(\"Optimal Number of Female Love Interests:\", optimal_nofemaleli)\n",
    "print(\"Optimal Number of Female Friendship Interests:\", optimal_nofemalefi)\n",
    "print(\"Optimal Number of LGBT characters:\", optimal_nolgbt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773cea1b-d338-49cb-99d4-4ab370d3bd2a",
   "metadata": {},
   "source": [
    "Overall, very similar to the previous model, except that we gained one female love interest!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db0f11-3ac3-406d-8ea8-b1282100ab47",
   "metadata": {},
   "source": [
    "### Relevant citations\n",
    "Code was referenced from https://www.datacamp.com/tutorial/machine-learning-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4067f7-bcc8-4798-82a2-30278b87eb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
